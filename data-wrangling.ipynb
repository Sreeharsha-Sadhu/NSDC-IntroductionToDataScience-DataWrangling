{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling and Missing Value Handling**\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "### Why is Data Wrangling Important?\n",
    "- **Real-world data** is often messy, containing missing values, inconsistencies, and irrelevant features.\n",
    "- **Unprocessed data** can lead to inaccurate insights and unreliable models.\n",
    "- **Effective data wrangling** transforms raw data into a structured, clean format suitable for analysis and machine learning.\n",
    "\n",
    "### **Key Steps in Data Wrangling:**\n",
    "1. **Data Cleaning** – Handling missing values, removing outliers, and standardizing formats.\n",
    "2. **Data Transformation** – Encoding categorical variables, normalizing numerical data, and feature engineering.\n",
    "3. **Data Integration** – Merging, reshaping, and aggregating data for better analysis.\n",
    "\n",
    "## **Dataset Used for Demonstration**\n",
    "We will use a **synthetic dataset** designed to teach **Data Wrangling** techniques by addressing common data issues. The dataset contains:\n",
    "\n",
    "### **1. Numerical Features**\n",
    "- **Age** – Contains missing values and outliers (e.g., unrealistic values).\n",
    "- **Salary** – Has missing values that require imputation.\n",
    "- **Work Experience** – Some missing entries, demonstrating handling techniques.\n",
    "- **Job Satisfaction Score** – Skewed distribution, useful for transformations.\n",
    "- **Customer Satisfaction Rating** – Ranges from 1 to 10, useful for normalization.\n",
    "\n",
    "### **2. Categorical Features**\n",
    "- **Name** – Contains duplicates and inconsistencies (e.g., different cases, extra spaces).\n",
    "- **Department** – Includes typos and inconsistent categories.\n",
    "- **Education Level** – Ordinal categorical variable requiring encoding.\n",
    "- **Remote Work** – Binary categorical feature useful for one-hot encoding.\n",
    "- **Performance Score** – Imbalanced target variable, demonstrating resampling techniques.\n",
    "\n",
    "### **3. Date and Currency Fields**\n",
    "- **Join Date** – Stored in mixed formats, demonstrating date parsing.\n",
    "- **Bonus** – Contains currency symbols (`$`, `€`), requiring conversion to numeric values.\n",
    "\n",
    "### **4. Key Data Wrangling Challenges Covered**\n",
    "- **Handling missing values** in Salary, Work Experience, and Age using imputation techniques.\n",
    "- **Dealing with outliers** in Age by capping, removing, or transforming values.\n",
    "- **Fixing inconsistencies** in categorical data through text standardization and deduplication.\n",
    "- **Encoding categorical variables** for machine learning compatibility.\n",
    "- **Normalizing and transforming numerical features** to improve data distributions.\n",
    "- **Addressing imbalanced target variables** through resampling techniques.\n",
    "\n",
    "This dataset is structured to provide hands-on experience in **Data Wrangling**, helping students learn essential techniques for real-world data preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T17:02:57.987006Z",
     "start_time": "2025-02-20T17:02:57.969628Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv(\"./data/data_wrangling_dataset.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "dataset.head()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ID     Name  Age   Salary   Join_Date Department Education_Level  \\\n",
       "0   1     Hank   39      NaN  2015-01-01         IT        Master's   \n",
       "1   2      Eve   33  63198.0  2015-01-02         HR     High School   \n",
       "2   3    David   41  43065.0  2015-01-03    Finance      Bachelor's   \n",
       "3   4    David   50  65048.0  2015-01-04        IT       Bachelor's   \n",
       "4   5  Charlie   32  80992.0  2015-01-05         HR     High School   \n",
       "\n",
       "   Work_Experience  Performance_Score   Bonus  Remote_Work  Job_Satisfaction  \\\n",
       "0              NaN                  5  €$6566            1          3.668445   \n",
       "1             23.0                  4    4969            1          0.423328   \n",
       "2             16.0                  4    6420            0          1.759563   \n",
       "3             20.0                  3    1607            0          3.000364   \n",
       "4              1.0                  4    6674            0          2.425639   \n",
       "\n",
       "   Customer_Satisfaction  \n",
       "0                      7  \n",
       "1                      3  \n",
       "2                      6  \n",
       "3                      6  \n",
       "4                      2  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Join_Date</th>\n",
       "      <th>Department</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Performance_Score</th>\n",
       "      <th>Bonus</th>\n",
       "      <th>Remote_Work</th>\n",
       "      <th>Job_Satisfaction</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hank</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>IT</td>\n",
       "      <td>Master's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>€$6566</td>\n",
       "      <td>1</td>\n",
       "      <td>3.668445</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Eve</td>\n",
       "      <td>33</td>\n",
       "      <td>63198.0</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>HR</td>\n",
       "      <td>High School</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4969</td>\n",
       "      <td>1</td>\n",
       "      <td>0.423328</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>David</td>\n",
       "      <td>41</td>\n",
       "      <td>43065.0</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6420</td>\n",
       "      <td>0</td>\n",
       "      <td>1.759563</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>David</td>\n",
       "      <td>50</td>\n",
       "      <td>65048.0</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>IT</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1607</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000364</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>32</td>\n",
       "      <td>80992.0</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>HR</td>\n",
       "      <td>High School</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6674</td>\n",
       "      <td>0</td>\n",
       "      <td>2.425639</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **1. Data Cleaning**\n",
    "\n",
    "## **1.1 Handling Missing Values**\n",
    "\n",
    "### **Why do Missing Values Occur?**\n",
    "- **Data collection errors** (e.g., sensor malfunctions, survey non-responses).\n",
    "- **Human errors** (e.g., incorrect data entry).\n",
    "- **Different data sources** (some sources may not have certain attributes).\n",
    "\n",
    "### **Methods to Handle Missing Values:**\n",
    "\n",
    "1. **Deletion (Dropping Missing Values):**\n",
    "   - **When to use?** If only a small percentage of data is missing.\n",
    "   - **Drawback:** Can result in loss of valuable data.\n",
    "\n",
    "2. **Imputation (Filling Missing Values):**\n",
    "   - **Mean/Median Imputation** (for numerical data) – works well if data is normally distributed.\n",
    "   - **Mode Imputation** (for categorical data) – replaces missing values with the most frequent value.\n",
    "   - **Forward/Backward Fill** (for time-series data) – fills missing values based on previous or next observations.\n",
    "   - **KNN Imputation** – predicts missing values based on similar data points.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T17:02:58.013068Z",
     "start_time": "2025-02-20T17:02:58.009732Z"
    }
   },
   "cell_type": "code",
   "source": "df = dataset.copy(deep=True)",
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T17:02:58.044427Z",
     "start_time": "2025-02-20T17:02:58.040617Z"
    }
   },
   "source": [
    "# Check missing values\n",
    "print(\"Missing values before handling:\")\n",
    "print(df.isnull().sum())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      "ID                         0\n",
      "Name                       0\n",
      "Age                        0\n",
      "Salary                   167\n",
      "Join_Date                  0\n",
      "Department                 0\n",
      "Education_Level            0\n",
      "Work_Experience          125\n",
      "Performance_Score          0\n",
      "Bonus                      0\n",
      "Remote_Work                0\n",
      "Job_Satisfaction           0\n",
      "Customer_Satisfaction      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T17:02:58.100391Z",
     "start_time": "2025-02-20T17:02:58.094700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drop rows with missing values (not recommended if data loss is high)\n",
    "df_dropped = df.dropna()"
   ],
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T17:02:58.175787Z",
     "start_time": "2025-02-20T17:02:58.138846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Impute numerical values (Age, Income) using Mean & Median\n",
    "imputer_mean = SimpleImputer(strategy='mean')\n",
    "df['Salary'] = imputer_mean.fit_transform(df[['Salary']])\n",
    "\n",
    "# Predictive Imputation using KNN (for Age & Income)\n",
    "knn_imputer = KNNImputer(n_neighbors=3)\n",
    "df[['Salary', 'Work_Experience']] = knn_imputer.fit_transform(df[['Salary', 'Work_Experience']])\n",
    "\n",
    "\n",
    "# Removing duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Check missing values after handling\n",
    "print(\"Missing values after handling:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df.head()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after handling:\n",
      "ID                       0\n",
      "Name                     0\n",
      "Age                      0\n",
      "Salary                   0\n",
      "Join_Date                0\n",
      "Department               0\n",
      "Education_Level          0\n",
      "Work_Experience          0\n",
      "Performance_Score        0\n",
      "Bonus                    0\n",
      "Remote_Work              0\n",
      "Job_Satisfaction         0\n",
      "Customer_Satisfaction    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   ID     Name  Age       Salary   Join_Date Department Education_Level  \\\n",
       "0   1     Hank   39  69834.74881  2015-01-01         IT        Master's   \n",
       "1   2      Eve   33  63198.00000  2015-01-02         HR     High School   \n",
       "2   3    David   41  43065.00000  2015-01-03    Finance      Bachelor's   \n",
       "3   4    David   50  65048.00000  2015-01-04        IT       Bachelor's   \n",
       "4   5  Charlie   32  80992.00000  2015-01-05         HR     High School   \n",
       "\n",
       "   Work_Experience  Performance_Score   Bonus  Remote_Work  Job_Satisfaction  \\\n",
       "0        17.666667                  5  €$6566            1          3.668445   \n",
       "1        23.000000                  4    4969            1          0.423328   \n",
       "2        16.000000                  4    6420            0          1.759563   \n",
       "3        20.000000                  3    1607            0          3.000364   \n",
       "4         1.000000                  4    6674            0          2.425639   \n",
       "\n",
       "   Customer_Satisfaction  \n",
       "0                      7  \n",
       "1                      3  \n",
       "2                      6  \n",
       "3                      6  \n",
       "4                      2  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Join_Date</th>\n",
       "      <th>Department</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Performance_Score</th>\n",
       "      <th>Bonus</th>\n",
       "      <th>Remote_Work</th>\n",
       "      <th>Job_Satisfaction</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hank</td>\n",
       "      <td>39</td>\n",
       "      <td>69834.74881</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>IT</td>\n",
       "      <td>Master's</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>€$6566</td>\n",
       "      <td>1</td>\n",
       "      <td>3.668445</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Eve</td>\n",
       "      <td>33</td>\n",
       "      <td>63198.00000</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>HR</td>\n",
       "      <td>High School</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4969</td>\n",
       "      <td>1</td>\n",
       "      <td>0.423328</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>David</td>\n",
       "      <td>41</td>\n",
       "      <td>43065.00000</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>6420</td>\n",
       "      <td>0</td>\n",
       "      <td>1.759563</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>David</td>\n",
       "      <td>50</td>\n",
       "      <td>65048.00000</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>IT</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1607</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000364</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>32</td>\n",
       "      <td>80992.00000</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>HR</td>\n",
       "      <td>High School</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>6674</td>\n",
       "      <td>0</td>\n",
       "      <td>2.425639</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T17:02:58.210638Z",
     "start_time": "2025-02-20T17:02:58.200532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Numerical Columns\n",
    "for col in ['Age', 'Salary', 'Work_Experience']:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Categorical Columns\n",
    "for col in ['Department', 'Education_Level', 'Remote_Work']:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "df.head()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreeh\\AppData\\Local\\Temp\\ipykernel_13860\\3469471385.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\sreeh\\AppData\\Local\\Temp\\ipykernel_13860\\3469471385.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\sreeh\\AppData\\Local\\Temp\\ipykernel_13860\\3469471385.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\sreeh\\AppData\\Local\\Temp\\ipykernel_13860\\3469471385.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\sreeh\\AppData\\Local\\Temp\\ipykernel_13860\\3469471385.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   ID     Name  Age       Salary   Join_Date Department Education_Level  \\\n",
       "0   1     Hank   39  69834.74881  2015-01-01         IT        Master's   \n",
       "1   2      Eve   33  63198.00000  2015-01-02         HR     High School   \n",
       "2   3    David   41  43065.00000  2015-01-03    Finance      Bachelor's   \n",
       "3   4    David   50  65048.00000  2015-01-04        IT       Bachelor's   \n",
       "4   5  Charlie   32  80992.00000  2015-01-05         HR     High School   \n",
       "\n",
       "   Work_Experience  Performance_Score   Bonus  Remote_Work  Job_Satisfaction  \\\n",
       "0        17.666667                  5  €$6566            1          3.668445   \n",
       "1        23.000000                  4    4969            1          0.423328   \n",
       "2        16.000000                  4    6420            0          1.759563   \n",
       "3        20.000000                  3    1607            0          3.000364   \n",
       "4         1.000000                  4    6674            0          2.425639   \n",
       "\n",
       "   Customer_Satisfaction  \n",
       "0                      7  \n",
       "1                      3  \n",
       "2                      6  \n",
       "3                      6  \n",
       "4                      2  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Join_Date</th>\n",
       "      <th>Department</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Performance_Score</th>\n",
       "      <th>Bonus</th>\n",
       "      <th>Remote_Work</th>\n",
       "      <th>Job_Satisfaction</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hank</td>\n",
       "      <td>39</td>\n",
       "      <td>69834.74881</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>IT</td>\n",
       "      <td>Master's</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>€$6566</td>\n",
       "      <td>1</td>\n",
       "      <td>3.668445</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Eve</td>\n",
       "      <td>33</td>\n",
       "      <td>63198.00000</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>HR</td>\n",
       "      <td>High School</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4969</td>\n",
       "      <td>1</td>\n",
       "      <td>0.423328</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>David</td>\n",
       "      <td>41</td>\n",
       "      <td>43065.00000</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>6420</td>\n",
       "      <td>0</td>\n",
       "      <td>1.759563</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>David</td>\n",
       "      <td>50</td>\n",
       "      <td>65048.00000</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>IT</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1607</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000364</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>32</td>\n",
       "      <td>80992.00000</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>HR</td>\n",
       "      <td>High School</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>6674</td>\n",
       "      <td>0</td>\n",
       "      <td>2.425639</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **1.2 Handling Outliers**\n",
    "\n",
    "### **What are Outliers?**\n",
    "- **Outliers** are extreme values that differ significantly from other observations.\n",
    "- They can be caused by **errors** or **natural variations** in the data.\n",
    "\n",
    "### **Methods to Detect and Remove Outliers:**\n",
    "\n",
    "1. **Z-Score Method**:\n",
    "   - Measures how many standard deviations a data point is from the mean.\n",
    "   - If the absolute Z-score is greater than 3, the value is considered an outlier.\n",
    "\n",
    "2. **Interquartile Range (IQR) Method**:\n",
    "   - Detects outliers by identifying values **outside 1.5 times the IQR**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T17:02:58.267693Z",
     "start_time": "2025-02-20T17:02:58.256507Z"
    }
   },
   "source": [
    "# Using Z-Score\n",
    "z_scores = np.abs(zscore(df['Age']))\n",
    "df = df[z_scores < 3]  # Removing outliers based on Z-score\n",
    "\n",
    "# Detecting Outliers using IQR\n",
    "Q1 = df['Salary'].quantile(0.25)\n",
    "Q3 = df['Salary'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "\n",
    "df = df[(df['Salary'] >= Q1 - 1.5 * IQR) & (df['Salary'] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ID     Name  Age       Salary   Join_Date Department Education_Level  \\\n",
       "0   1     Hank   39  69834.74881  2015-01-01         IT        Master's   \n",
       "1   2      Eve   33  63198.00000  2015-01-02         HR     High School   \n",
       "2   3    David   41  43065.00000  2015-01-03    Finance      Bachelor's   \n",
       "3   4    David   50  65048.00000  2015-01-04        IT       Bachelor's   \n",
       "4   5  Charlie   32  80992.00000  2015-01-05         HR     High School   \n",
       "\n",
       "   Work_Experience  Performance_Score   Bonus  Remote_Work  Job_Satisfaction  \\\n",
       "0        17.666667                  5  €$6566            1          3.668445   \n",
       "1        23.000000                  4    4969            1          0.423328   \n",
       "2        16.000000                  4    6420            0          1.759563   \n",
       "3        20.000000                  3    1607            0          3.000364   \n",
       "4         1.000000                  4    6674            0          2.425639   \n",
       "\n",
       "   Customer_Satisfaction  \n",
       "0                      7  \n",
       "1                      3  \n",
       "2                      6  \n",
       "3                      6  \n",
       "4                      2  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Join_Date</th>\n",
       "      <th>Department</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Performance_Score</th>\n",
       "      <th>Bonus</th>\n",
       "      <th>Remote_Work</th>\n",
       "      <th>Job_Satisfaction</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hank</td>\n",
       "      <td>39</td>\n",
       "      <td>69834.74881</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>IT</td>\n",
       "      <td>Master's</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>€$6566</td>\n",
       "      <td>1</td>\n",
       "      <td>3.668445</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Eve</td>\n",
       "      <td>33</td>\n",
       "      <td>63198.00000</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>HR</td>\n",
       "      <td>High School</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4969</td>\n",
       "      <td>1</td>\n",
       "      <td>0.423328</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>David</td>\n",
       "      <td>41</td>\n",
       "      <td>43065.00000</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>6420</td>\n",
       "      <td>0</td>\n",
       "      <td>1.759563</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>David</td>\n",
       "      <td>50</td>\n",
       "      <td>65048.00000</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>IT</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1607</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000364</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>32</td>\n",
       "      <td>80992.00000</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>HR</td>\n",
       "      <td>High School</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>6674</td>\n",
       "      <td>0</td>\n",
       "      <td>2.425639</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **1.4 Standardizing Data Formats**\n",
    "\n",
    "### **Why Standardization of Data Formats is Important?**\n",
    "\n",
    "- Ensures Consistency: Data often comes in different formats, making uniform processing essential.\n",
    "\n",
    "- Facilitates Comparisons: Uniform formats enable accurate analysis and computations.\n",
    "\n",
    "- Reduces Errors: Inconsistent formats can lead to misinterpretations and processing issues.\n",
    "\n",
    "- Improves Data Quality: Standardization simplifies data cleaning and validation.\n",
    "\n",
    "### **Common Data Formats to Standardize**\n",
    "\n",
    "1. **Date and Time Standardization:** Standardizing date formats ensures accurate sorting, filtering, and time-based analysis. Using a universally accepted format, such as ISO 8601, enhances consistency.\n",
    "\n",
    "2. **Numeric Data Standardization:** Removing extra characters like currency symbols and ensuring a consistent decimal notation is essential for correct calculations.\n",
    "\n",
    "3. **Categorical Data Standardization:** Variations in categorical values (e.g., different capitalizations or abbreviations) can cause inconsistencies. Standardizing these values improves reliability.\n",
    "\n",
    "4. **Text and String Formatting:** Removing unnecessary spaces, special characters, and ensuring uniform capitalization enhances text processing.\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T17:02:58.360546Z",
     "start_time": "2025-02-20T17:02:58.341074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Standardizing date format\n",
    "df['Join_Date'] = pd.to_datetime(df['Join_Date'], errors='coerce')\n",
    "\n",
    "# Converting currency column to numeric using different approaches\n",
    "df['Bonus'] = df['Bonus'].replace({r'\\$': '', r'€': ''}, regex=True).astype(int)\n",
    "\n",
    "# Standardizing numeric data\n",
    "df['Salary'] = df['Salary'].astype(int)\n",
    "df['Job_Satisfaction'] = df['Job_Satisfaction'].astype(int)\n",
    "df['Work_Experience'] = df['Work_Experience'].astype(int)\n",
    "\n",
    "df['Name'] = df['Name'].str.strip().str.title()\n",
    "\n",
    "\n",
    "\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ID     Name  Age  Salary  Join_Date Department Education_Level  \\\n",
       "0   1     Hank   39   69834 2015-01-01         IT        Master's   \n",
       "1   2      Eve   33   63198 2015-01-02         HR     High School   \n",
       "2   3    David   41   43065 2015-01-03    Finance      Bachelor's   \n",
       "3   4    David   50   65048 2015-01-04        IT       Bachelor's   \n",
       "4   5  Charlie   32   80992 2015-01-05         HR     High School   \n",
       "\n",
       "   Work_Experience  Performance_Score  Bonus  Remote_Work  Job_Satisfaction  \\\n",
       "0               17                  5   6566            1                 3   \n",
       "1               23                  4   4969            1                 0   \n",
       "2               16                  4   6420            0                 1   \n",
       "3               20                  3   1607            0                 3   \n",
       "4                1                  4   6674            0                 2   \n",
       "\n",
       "   Customer_Satisfaction  \n",
       "0                      7  \n",
       "1                      3  \n",
       "2                      6  \n",
       "3                      6  \n",
       "4                      2  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Join_Date</th>\n",
       "      <th>Department</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Performance_Score</th>\n",
       "      <th>Bonus</th>\n",
       "      <th>Remote_Work</th>\n",
       "      <th>Job_Satisfaction</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hank</td>\n",
       "      <td>39</td>\n",
       "      <td>69834</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>IT</td>\n",
       "      <td>Master's</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>6566</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Eve</td>\n",
       "      <td>33</td>\n",
       "      <td>63198</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>HR</td>\n",
       "      <td>High School</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>4969</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>David</td>\n",
       "      <td>41</td>\n",
       "      <td>43065</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>6420</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>David</td>\n",
       "      <td>50</td>\n",
       "      <td>65048</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>IT</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1607</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>32</td>\n",
       "      <td>80992</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>HR</td>\n",
       "      <td>High School</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6674</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **2. Data Pre-processing**\n",
    "\n",
    "## **2.1 Encoding Categorical Variables**\n",
    "\n",
    "### **Why do we need Encoding?**\n",
    "- Machine learning models require **numerical data**.\n",
    "- Encoding converts categorical values into numbers.\n",
    "\n",
    "### **Types of Encoding:**\n",
    "\n",
    "1. **Label Encoding**:\n",
    "   - Assigns **a unique integer** to each category.\n",
    "   - **Best for** ordinal categorical data (e.g., Small, Medium, Large).\n",
    "\n",
    "2. **One-Hot Encoding**:\n",
    "   - Creates separate **binary columns** for each category.\n",
    "   - **Best for** nominal categorical data (e.g., Cities, Colors).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T17:02:58.430693Z",
     "start_time": "2025-02-20T17:02:58.421870Z"
    }
   },
   "source": [
    "# Encoding categorical variables using multiple techniques\n",
    "label_encoder = LabelEncoder()\n",
    "df['Education_Level'] = label_encoder.fit_transform(df['Education_Level'])  # Label Encoding\n",
    "\n",
    "# Alternative method: (One-Hot Encoding)\n",
    "# df = pd.get_dummies(df, columns=['Department', 'Remote_Work'], drop_first=True)\n",
    "\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ID     Name  Age  Salary  Join_Date Department  Education_Level  \\\n",
       "0   1     Hank   39   69834 2015-01-01         IT                2   \n",
       "1   2      Eve   33   63198 2015-01-02         HR                1   \n",
       "2   3    David   41   43065 2015-01-03    Finance                0   \n",
       "3   4    David   50   65048 2015-01-04        IT                 0   \n",
       "4   5  Charlie   32   80992 2015-01-05         HR                1   \n",
       "\n",
       "   Work_Experience  Performance_Score  Bonus  Remote_Work  Job_Satisfaction  \\\n",
       "0               17                  5   6566            1                 3   \n",
       "1               23                  4   4969            1                 0   \n",
       "2               16                  4   6420            0                 1   \n",
       "3               20                  3   1607            0                 3   \n",
       "4                1                  4   6674            0                 2   \n",
       "\n",
       "   Customer_Satisfaction  \n",
       "0                      7  \n",
       "1                      3  \n",
       "2                      6  \n",
       "3                      6  \n",
       "4                      2  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Join_Date</th>\n",
       "      <th>Department</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Performance_Score</th>\n",
       "      <th>Bonus</th>\n",
       "      <th>Remote_Work</th>\n",
       "      <th>Job_Satisfaction</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hank</td>\n",
       "      <td>39</td>\n",
       "      <td>69834</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>6566</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Eve</td>\n",
       "      <td>33</td>\n",
       "      <td>63198</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>HR</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>4969</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>David</td>\n",
       "      <td>41</td>\n",
       "      <td>43065</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Finance</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>6420</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>David</td>\n",
       "      <td>50</td>\n",
       "      <td>65048</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>IT</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1607</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>32</td>\n",
       "      <td>80992</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>HR</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6674</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **2.1 Handling Imbalanced Datasets**\n",
    "\n",
    "- **Why It Matters**: In imbalanced datasets, one class significantly outweighs others, leading to biased models that favor the dominant class.\n",
    "- **Strategies for Handling Imbalance**:\n",
    "  - **Resampling Methods**: Oversampling the minority class or undersampling the majority class can help balance the dataset.\n",
    "  - **Synthetic Data Generation**: Techniques like SMOTE (Synthetic Minority Over-sampling Technique) generate synthetic examples to balance class distribution.\n",
    "  - **Algorithmic Approaches**: Some machine learning models handle imbalance better by adjusting class weights.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T17:02:58.528635Z",
     "start_time": "2025-02-20T17:02:58.507153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Handling imbalanced datasets\n",
    "X = df.drop(columns=['Performance_Score', 'Name'])\n",
    "y = df['Performance_Score']\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "df = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "df.head()"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13860\\1719722250.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Handling imbalanced datasets\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Performance_Score'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'Name'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Performance_Score'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0msmote\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSMOTE\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mX_resampled\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_resampled\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msmote\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_resample\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mX_resampled\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_resampled\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\imblearn\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    199\u001B[0m         \u001B[0my_resampled\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0marray\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mlike\u001B[0m \u001B[0mof\u001B[0m \u001B[0mshape\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mn_samples_new\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m             \u001B[0mThe\u001B[0m \u001B[0mcorresponding\u001B[0m \u001B[0mlabel\u001B[0m \u001B[0mof\u001B[0m \u001B[1;33m`\u001B[0m\u001B[0mX_resampled\u001B[0m\u001B[1;33m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    201\u001B[0m         \"\"\"\n\u001B[1;32m--> 202\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_resample\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1385\u001B[0m                 skip_parameter_validation=(\n\u001B[0;32m   1386\u001B[0m                     \u001B[0mprefer_skip_nested_validation\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mglobal_skip_validation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1387\u001B[0m                 \u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1388\u001B[0m             \u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1389\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mfit_method\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\imblearn\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m     95\u001B[0m             \u001B[0mThe\u001B[0m \u001B[0mcorresponding\u001B[0m \u001B[0mlabel\u001B[0m \u001B[0mof\u001B[0m \u001B[1;33m`\u001B[0m\u001B[0mX_resampled\u001B[0m\u001B[1;33m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     96\u001B[0m         \"\"\"\n\u001B[0;32m     97\u001B[0m         \u001B[0mcheck_classification_targets\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     98\u001B[0m         \u001B[0marrays_transformer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mArraysTransformer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 99\u001B[1;33m         \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbinarize_y\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_check_X_y\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    100\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    101\u001B[0m         self.sampling_strategy_ = check_sampling_strategy(\n\u001B[0;32m    102\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msampling_strategy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sampling_type\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\imblearn\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y, accept_sparse)\u001B[0m\n\u001B[0;32m    153\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_check_X_y\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    154\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0maccept_sparse\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    155\u001B[0m             \u001B[0maccept_sparse\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m\"csr\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"csc\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    156\u001B[0m         \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbinarize_y\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_target_type\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindicate_one_vs_all\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 157\u001B[1;33m         \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalidate_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreset\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    158\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbinarize_y\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[0m\n\u001B[0;32m   2957\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;34m\"estimator\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcheck_y_params\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2958\u001B[0m                 \u001B[0mcheck_y_params\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mdefault_check_params\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2959\u001B[0m             \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"y\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2960\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2961\u001B[1;33m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2962\u001B[0m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2963\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2964\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mcheck_params\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"ensure_2d\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1366\u001B[0m         \u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1367\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1368\u001B[0m     \u001B[0mensure_all_finite\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_deprecate_force_all_finite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mforce_all_finite\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mensure_all_finite\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1369\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1370\u001B[1;33m     X = check_array(\n\u001B[0m\u001B[0;32m   1371\u001B[0m         \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1372\u001B[0m         \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1373\u001B[0m         \u001B[0maccept_large_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_large_sparse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m   1052\u001B[0m                         \u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1054\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1055\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_asarray_with_order\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mxp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1056\u001B[1;33m             \u001B[1;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1057\u001B[0m                 raise ValueError(\n\u001B[0;32m   1058\u001B[0m                     \u001B[1;34m\"Complex data not supported\\n{}\\n\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1059\u001B[0m                 \u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(array, dtype, order, copy, xp, device)\u001B[0m\n\u001B[0;32m    835\u001B[0m         \u001B[1;31m# Use NumPy API to support order\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    836\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcopy\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    837\u001B[0m             \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    838\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 839\u001B[1;33m             \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    840\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    841\u001B[0m         \u001B[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    842\u001B[0m         \u001B[1;31m# container that is consistent with the input's namespace.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, dtype, copy)\u001B[0m\n\u001B[0;32m   2149\u001B[0m     def __array__(\n\u001B[0;32m   2150\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnpt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDTypeLike\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mbool_t\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2151\u001B[0m     \u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2152\u001B[0m         \u001B[0mvalues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2153\u001B[1;33m         \u001B[0marr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2154\u001B[0m         if (\n\u001B[0;32m   2155\u001B[0m             \u001B[0mastype_is_view\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2156\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0musing_copy_on_write\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: float() argument must be a string or a real number, not 'Timestamp'"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **2.2 Feature Selection**\n",
    "- **Why It Matters**: Irrelevant or low-variance features can add noise and reduce model performance.\n",
    "- **Methods for Feature Selection**:\n",
    "  - **Variance Thresholding**: Removing features with very low variance helps eliminate those that contribute little to predictive power.\n",
    "  - **Correlation Analysis**: Highly correlated features can be redundant and may be removed to simplify the model.\n",
    "  - **Model-Based Selection**: Feature importance"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T17:02:58.581903700Z",
     "start_time": "2025-02-20T16:55:11.053387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature selection: Dropping low-variance columns manually\n",
    "threshold = 0.01 * (1 - 0.01)\n",
    "low_variance_cols = [col for col in df.columns if df[col].var() < threshold]\n",
    "df = df.drop(columns=low_variance_cols)"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "could not convert string to float: 'hank'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\pandas\\core\\nanops.py:85\u001B[0m, in \u001B[0;36mdisallow.__call__.<locals>._f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 85\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;66;03m# we want to transform an object array\u001B[39;00m\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;66;03m# ValueError message to the more typical TypeError\u001B[39;00m\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;66;03m# e.g. this is normally a disallowed function on\u001B[39;00m\n\u001B[0;32m     90\u001B[0m     \u001B[38;5;66;03m# object arrays that contain strings\u001B[39;00m\n",
      "File \u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001B[0m, in \u001B[0;36mbottleneck_switch.__call__.<locals>.f\u001B[1;34m(values, axis, skipna, **kwds)\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 147\u001B[0m     result \u001B[38;5;241m=\u001B[39m alt(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\pandas\\core\\nanops.py:1013\u001B[0m, in \u001B[0;36mnanvar\u001B[1;34m(values, axis, skipna, ddof, mask)\u001B[0m\n\u001B[0;32m   1007\u001B[0m \u001B[38;5;66;03m# xref GH10242\u001B[39;00m\n\u001B[0;32m   1008\u001B[0m \u001B[38;5;66;03m# Compute variance via two-pass algorithm, which is stable against\u001B[39;00m\n\u001B[0;32m   1009\u001B[0m \u001B[38;5;66;03m# cancellation errors and relatively accurate for small numbers of\u001B[39;00m\n\u001B[0;32m   1010\u001B[0m \u001B[38;5;66;03m# observations.\u001B[39;00m\n\u001B[0;32m   1011\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m   1012\u001B[0m \u001B[38;5;66;03m# See https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\u001B[39;00m\n\u001B[1;32m-> 1013\u001B[0m avg \u001B[38;5;241m=\u001B[39m _ensure_numeric(values\u001B[38;5;241m.\u001B[39msum(axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat64)) \u001B[38;5;241m/\u001B[39m count\n\u001B[0;32m   1014\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\numpy\\_core\\_methods.py:52\u001B[0m, in \u001B[0;36m_sum\u001B[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_sum\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     51\u001B[0m          initial\u001B[38;5;241m=\u001B[39m_NoValue, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m---> 52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'hank'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Feature selection: Dropping low-variance columns manually\u001B[39;00m\n\u001B[0;32m      2\u001B[0m threshold \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.01\u001B[39m \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m low_variance_cols \u001B[38;5;241m=\u001B[39m [col \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m df\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;28;01mif\u001B[39;00m df[col]\u001B[38;5;241m.\u001B[39mvar() \u001B[38;5;241m<\u001B[39m threshold]\n\u001B[0;32m      4\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39mlow_variance_cols)\n",
      "File \u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\pandas\\core\\series.py:6581\u001B[0m, in \u001B[0;36mSeries.var\u001B[1;34m(self, axis, skipna, ddof, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m   6572\u001B[0m \u001B[38;5;129m@doc\u001B[39m(make_doc(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvar\u001B[39m\u001B[38;5;124m\"\u001B[39m, ndim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m   6573\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvar\u001B[39m(\n\u001B[0;32m   6574\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   6579\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   6580\u001B[0m ):\n\u001B[1;32m-> 6581\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m NDFrame\u001B[38;5;241m.\u001B[39mvar(\u001B[38;5;28mself\u001B[39m, axis, skipna, ddof, numeric_only, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\pandas\\core\\generic.py:12346\u001B[0m, in \u001B[0;36mNDFrame.var\u001B[1;34m(self, axis, skipna, ddof, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12338\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvar\u001B[39m(\n\u001B[0;32m  12339\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m  12340\u001B[0m     axis: Axis \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  12344\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  12345\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Series \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[1;32m> 12346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stat_function_ddof(\n\u001B[0;32m  12347\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvar\u001B[39m\u001B[38;5;124m\"\u001B[39m, nanops\u001B[38;5;241m.\u001B[39mnanvar, axis, skipna, ddof, numeric_only, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m  12348\u001B[0m     )\n",
      "File \u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\pandas\\core\\generic.py:12322\u001B[0m, in \u001B[0;36mNDFrame._stat_function_ddof\u001B[1;34m(self, name, func, axis, skipna, ddof, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12319\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mno_default:\n\u001B[0;32m  12320\u001B[0m     axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m> 12322\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reduce(\n\u001B[0;32m  12323\u001B[0m     func, name, axis\u001B[38;5;241m=\u001B[39maxis, numeric_only\u001B[38;5;241m=\u001B[39mnumeric_only, skipna\u001B[38;5;241m=\u001B[39mskipna, ddof\u001B[38;5;241m=\u001B[39mddof\n\u001B[0;32m  12324\u001B[0m )\n",
      "File \u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\pandas\\core\\series.py:6457\u001B[0m, in \u001B[0;36mSeries._reduce\u001B[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001B[0m\n\u001B[0;32m   6452\u001B[0m     \u001B[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001B[39;00m\n\u001B[0;32m   6453\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m   6454\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSeries.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not allow \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwd_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumeric_only\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   6455\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwith non-numeric dtypes.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   6456\u001B[0m     )\n\u001B[1;32m-> 6457\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m op(delegate, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32mF:\\DevCache\\conda\\envs\\main\\Lib\\site-packages\\pandas\\core\\nanops.py:92\u001B[0m, in \u001B[0;36mdisallow.__call__.<locals>._f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;66;03m# we want to transform an object array\u001B[39;00m\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;66;03m# ValueError message to the more typical TypeError\u001B[39;00m\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;66;03m# e.g. this is normally a disallowed function on\u001B[39;00m\n\u001B[0;32m     90\u001B[0m     \u001B[38;5;66;03m# object arrays that contain strings\u001B[39;00m\n\u001B[0;32m     91\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_object_dtype(args[\u001B[38;5;241m0\u001B[39m]):\n\u001B[1;32m---> 92\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: could not convert string to float: 'hank'"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **3. Data Transformation**\n",
    "\n",
    "## **3.1 Scaling & Normalization**\n",
    "\n",
    "### **Why Scale Data?**\n",
    "- Ensures that **all features contribute equally** to the model.\n",
    "- Improves performance in algorithms like KNN, SVM, and PCA.\n",
    "\n",
    "### **Methods:**\n",
    "1. **Min-Max Scaling**: Scales data to a range **[0,1]**.\n",
    "2. **Standardization (Z-score)**: Centers data around **mean = 0, std = 1**.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "df[['Age', 'Salary', 'Work Experience']] = scaler.fit_transform(df[['Age', 'Salary', 'Work Experience']])\n",
    "\n",
    "\n",
    "# Standardization\n",
    "df[['Age', 'Salary', 'Work Experience']] = StandardScaler().fit_transform(df[['Age', 'Salary', 'Work Experience']])\n",
    "\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Log transformation for skewed data using numpy\n",
    "for col in ['Salary', 'Bonus']:\n",
    "    df[col] = np.log1p(df[col])\n",
    "\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Feature engineering: Creating new features\n",
    "df['Experience per Year'] = df['Work Experience'] / (df['Age'] + 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.to_csv(\"cleaned_synthetic_data.csv\", index=False)",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  },
  "prev_pub_hash": "0f2053140168387dde22a52dafe4fef4f297eb98b70601c31c5dbae85ffb8130"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
